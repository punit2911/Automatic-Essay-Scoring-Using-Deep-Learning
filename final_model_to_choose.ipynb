{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\admi\\AppData\\Local\\Temp\\ipykernel_28272\\3363072088.py:68: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your .h5 models\n",
    "lstm_model = load_model('final_lstm.h5')  # Replace with actual path\n",
    "gru_model = load_model('final_gru.h5')    # Replace with actual path\n",
    "\n",
    "# Preparing Dataset\n",
    "df = pd.read_csv(\"Dataset/training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1')\n",
    "df.dropna(axis=1, inplace=True)\n",
    "df.drop(columns=['domain1_score', 'rater1_domain1', 'rater2_domain1'], inplace=True, axis=1)\n",
    "\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "df['domain1_score'] = temp['final_score']\n",
    "\n",
    "# Make Dataset\n",
    "y = df['domain1_score']\n",
    "df.drop('domain1_score', inplace=True, axis=1)\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# PREPROCESSING\n",
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()\n",
    "train_sents = []\n",
    "test_sents = []\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def sent2word(x):\n",
    "    x = re.sub(\"[^A-Za-z]\", \" \", x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words = x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words = []\n",
    "    for i in raw:\n",
    "        if len(i) > 0:\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents += essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents += essay2word(i)\n",
    "\n",
    "# Preparing WORD2VEC and Vectorizing the essays\n",
    "num_features = 300\n",
    "model = Word2Vec(train_sents, workers=4, vector_size=num_features, min_count=40, window=10, sample=1e-3)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec, model.wv[i])\n",
    "    if noOfWords > 0:\n",
    "        vec = np.divide(vec, noOfWords)\n",
    "    return vec\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c = 0\n",
    "    essay_vecs = np.zeros((len(essays), num_features), dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c += 1\n",
    "    return essay_vecs\n",
    "\n",
    "# Vectorizing the essays\n",
    "clean_train = [sent2word(i) for i in train_e]\n",
    "clean_test = [sent2word(i) for i in test_e]\n",
    "\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "testing_vectors = getVecs(clean_test, model, num_features)\n",
    "\n",
    "# Reshaping the vectors for LSTM and GRU\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "\n",
    "# Evaluate both models\n",
    "lstm_predictions = lstm_model.predict(testing_vectors)\n",
    "gru_predictions = gru_model.predict(testing_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Predictions Shape: (3893,)\n",
      "GRU Predictions Shape: (3893,)\n",
      "LSTM Model Metrics:\n",
      "Mean Absolute Error: 1.4317829102744732\n",
      "Mean Squared Error: 3.4872927366571815\n",
      "R² Score: 0.42001307454040815\n",
      "\n",
      "GRU Model Metrics:\n",
      "Mean Absolute Error: 1.4056211550132247\n",
      "Mean Squared Error: 3.374278022683318\n",
      "R² Score: 0.43880904649893904\n",
      "\n",
      "GRU model performs better and will be deployed to the frontend.\n"
     ]
    }
   ],
   "source": [
    "# Remove Cohen's Kappa and use regression metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Flatten the predictions to be 1D arrays\n",
    "lstm_predictions = np.squeeze(lstm_predictions)\n",
    "gru_predictions = np.squeeze(gru_predictions)\n",
    "\n",
    "# Check the shape of the predictions\n",
    "print(\"LSTM Predictions Shape:\", lstm_predictions.shape)\n",
    "print(\"GRU Predictions Shape:\", gru_predictions.shape)\n",
    "\n",
    "# Flatten y_test as well to ensure it's 1D\n",
    "y_test = np.array(y_test).flatten()\n",
    "\n",
    "# Calculate MAE and MSE\n",
    "lstm_mae = np.mean(np.abs(lstm_predictions - y_test))\n",
    "gru_mae = np.mean(np.abs(gru_predictions - y_test))\n",
    "\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "gru_mse = mean_squared_error(y_test, gru_predictions)\n",
    "\n",
    "# Calculate R² score (coefficient of determination)\n",
    "lstm_r2 = r2_score(y_test, lstm_predictions)\n",
    "gru_r2 = r2_score(y_test, gru_predictions)\n",
    "\n",
    "# Print metrics for comparison\n",
    "print(\"LSTM Model Metrics:\")\n",
    "print(f\"Mean Absolute Error: {lstm_mae}\")\n",
    "print(f\"Mean Squared Error: {lstm_mse}\")\n",
    "print(f\"R² Score: {lstm_r2}\")\n",
    "\n",
    "print(\"\\nGRU Model Metrics:\")\n",
    "print(f\"Mean Absolute Error: {gru_mae}\")\n",
    "print(f\"Mean Squared Error: {gru_mse}\")\n",
    "print(f\"R² Score: {gru_r2}\")\n",
    "\n",
    "# Select the best model based on MAE or other regression metrics\n",
    "if gru_mae < lstm_mae:\n",
    "    print(\"\\nGRU model performs better and will be deployed to the frontend.\")\n",
    "    best_model = gru_model\n",
    "else:\n",
    "    print(\"\\nLSTM model performs better and will be deployed to the frontend.\")\n",
    "    best_model = lstm_model\n",
    "\n",
    "# Save the selected model for deployment\n",
    "best_model.save('best_model_for_deployment.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
